{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30d3ba5-5d15-4a37-8483-1592fcd6db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bertviz import head_view, model_view\n",
    "\n",
    "from transformer_implementation import Transformer, Tokenizer, TransformerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99d1ac-451d-45c8-9a5d-28799680a1b9",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1014fd-c546-4959-b9b6-996af4f2dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4a4183-8126-4b94-8130-7541b0ca4d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(\n",
      "\tself.tokenizer=<transformer_implementation.Tokenizer.Tokenizer object at 0x000001EFFFA00A90>,\n",
      "\tself.block_size=256,\n",
      "\tself.batch_size=12,\n",
      "\tself.n_layer=6,\n",
      "\tself.n_head=8,\n",
      "\tself.n_embd=256,\n",
      "\tself.dropout=0.1,\n",
      "\tself.bias=False,\n",
      "\tself.device='cuda',\n",
      "\tself.learning_rate=0.0003,\n",
      "\tself.max_epochs=100,\n",
      "\tself.max_iters=2500,\n",
      "\tself.eval_iters=250,\n",
      "\tself.train_data_size=30000,\n",
      "\tself.visualize=True,\n",
      "\tself.vocab_size=100277,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# init config\n",
    "config = TransformerConfig(\n",
    "    tokenizer,\n",
    "    block_size = 256,\n",
    "    batch_size = 12,\n",
    "    n_layer = 6, # 6,\n",
    "    n_head = 8,\n",
    "    n_embd = 256,\n",
    "    max_epochs=100,\n",
    "    train_data_size = 30000, # batch * 500 iters\n",
    "    max_iters = 2500,\n",
    "    eval_iters = 250,\n",
    "    visualize = True,\n",
    ")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0766891a-8164-45b0-8b7e-ce76eebaa75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encoder parameters: 30.39M\n",
      "number of Decoder parameters: 31.97M\n",
      "Total number of parameters: 62.36M\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Transformer(config)\n",
    "model.load_model(\"./out/transformer-train.pth\")\n",
    "model.eval()\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e28e8b8-a6b7-4591-9ac3-ffc8770ed362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentences, tokenizer, model, config):\n",
    "    \"\"\"\n",
    "    This function tokenizes input sentences, translates them using the provided model,\n",
    "    and decodes the output into human-readable text. It also returns the attention dictionary from the model.\n",
    "\n",
    "    Args:\n",
    "        - sentences (list[str]): List of sentences to be translated.\n",
    "        - tokenizer (Tokenizer): Tokenizer used for encoding and decoding sequences.\n",
    "        - model (Transformer): The model used for translation.\n",
    "        - config (Config): The configuration object that defines parameters like block_size.\n",
    "\n",
    "    Returns:\n",
    "        - decode_output (list[str]): List of translated sentences.\n",
    "        - attn (dict): Dictionary containing attention information from the last layer of the model.\n",
    "    \"\"\"\n",
    "    # Tokenize sentences\n",
    "    tknzr = tokenizer.encoder\n",
    "    sequences = []\n",
    "    masks =  []\n",
    "\n",
    "    # Encode each sentence and add it to the list of sequences\n",
    "    for sentence in sentences:\n",
    "        sequence = tokenizer.sequence_padding(tknzr.encode(sentence), config.block_size).unsqueeze(dim=0)\n",
    "        mask = tokenizer.generate_padding_mask(sequence)\n",
    "        sequences.append(sequence)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Concatenate the sequences into a tensor\n",
    "    sequences = torch.cat(sequences, dim=0)\n",
    "    masks = torch.cat(masks, dim=0)\n",
    "\n",
    "    # Set the model to evaluation mode and translate sentences\n",
    "    model.eval()\n",
    "    outputs, attn = model.inference(\n",
    "        sequences.to(config.device),\n",
    "        max_length=config.block_size,\n",
    "        src_mask=masks.to(config.device)\n",
    "    )\n",
    "    # Initialize a list to store the decoded sentences\n",
    "    decode_output = []\n",
    "    # Decode each output sequence and add it to the list of decoded outputs\n",
    "    for output in outputs:\n",
    "        output = tokenizer.sequence_cleaner(output)\n",
    "        decode_output += [tknzr.decode(output)]\n",
    "\n",
    "    # Return the decoded sentences and the attention dictionary\n",
    "    return decode_output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82890e5-6545-4d99-aac5-c687324c8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [\"\"\"You are the champion!\"\"\"]\n",
    "# expected_output = ['Je suis un professeur.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d52ba69-9237-452e-923e-2749af2125ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiba\\.virtualenvs\\transformer-LWcVpt7F\\Lib\\site-packages\\torch\\utils\\checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/256tensor([[[-14.2131,  -1.2201, -14.2127,  ..., -14.2144, -14.2192, -14.2208]]],\n",
      "       device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "13\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m outputs, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m, in \u001b[0;36mtranslate\u001b[1;34m(sentences, tokenizer, model, config)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode and translate sentences\u001b[39;00m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 34\u001b[0m outputs, attn \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Initialize a list to store the decoded sentences\u001b[39;00m\n\u001b[0;32m     40\u001b[0m decode_output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\.virtualenvs\\transformer-LWcVpt7F\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\thiba\\Documents\\Professionnel\\data-science\\Kaggle\\transformer\\transformer_implementation\\Transformer.py:111\u001b[0m, in \u001b[0;36mTransformer.inference\u001b[1;34m(self, src, src_mask, tgt_mask, max_length, top_p)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m2\u001b[39m)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m output_token \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m2\u001b[39m)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Append the output token to the output sequence\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs, attentions = translate(input, tokenizer, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704cd98-63d0-48cd-809c-18dd179be8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d80d0-2107-4e6c-b8b6-c49012308c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_attn(input, output, attentions, batch: int = 0):\n",
    "    \"\"\"\n",
    "    This function formats the attention outputs and tokenized inputs and outputs for easier interpretation and visualization.\n",
    "\n",
    "    Args:\n",
    "        - input (str): The original input sentence.\n",
    "        - output (str): The translated output sentence.\n",
    "        - attentions (dict): A dictionary containing the attention information from the model.\n",
    "        - batch (int, optional): The batch index to format. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        - tokens_input (list[str]): The tokenized input sentence, padded to max_len.\n",
    "        - tokens_output (list[str]): The tokenized output sentence, padded to max_len.\n",
    "        - tensor_encoder_attn (torch.Tensor): The attention tensor for the encoder, trimmed and reshaped.\n",
    "        - tensor_cross_attn (torch.Tensor): The cross-attention tensor, trimmed and reshaped.\n",
    "        - tensor_decoder_attn (torch.Tensor): The attention tensor for the decoder, trimmed and reshaped.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stack the attention tensors along a new dimension\n",
    "    tensor_encoder_attn = torch.stack(attentions['encoder_attn'], dim=0)\n",
    "    tensor_cross_attn = torch.stack(attentions['cross_attn'], dim=0)\n",
    "    tensor_decoder_attn = torch.stack(attentions['decoder_attn'], dim=0)\n",
    "\n",
    "    # Tokenize the input and output sentences\n",
    "    tokens_input = tokenizer.tokenize_from_str(input[batch])\n",
    "    tokens_output = tokenizer.tokenize_from_str(output[batch])\n",
    "\n",
    "    # Find the maximum length of the input and output tokens\n",
    "    max_len = min(len(tokens_input), len(tokens_output))\n",
    "\n",
    "    # If the input tokens are shorter than the max length, pad with empty strings\n",
    "    if len(tokens_input) < max_len:\n",
    "        tokens_input = tokens_input + [''] * (max_len - len(tokens_input))\n",
    "    # Otherwise, pad the output tokens with empty strings\n",
    "    else:\n",
    "        tokens_output = tokens_output + [''] * (max_len - len(tokens_output))\n",
    "\n",
    "    # Trim and reshape the attention tensors\n",
    "    tensor_encoder_attn = tensor_encoder_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "    tensor_cross_attn = tensor_cross_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "    tensor_decoder_attn = tensor_decoder_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "\n",
    "    # Return the formatted tokens and attention tensors\n",
    "    return tokens_input, tokens_output, tensor_encoder_attn, tensor_cross_attn, tensor_decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4df39-943a-446f-819a-e97e93129407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input,\\\n",
    "tokens_output,\\\n",
    "tensor_encoder_attn,\\\n",
    "tensor_cross_attn,\\\n",
    "tensor_decoder_attn = format_attn(input, outputs, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbf390-5e54-4fd6-9274-e3c9d19d4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_model_view = model_view(\n",
    "    encoder_attention=tensor_encoder_attn,\n",
    "    decoder_attention=tensor_decoder_attn,\n",
    "    cross_attention=tensor_cross_attn,\n",
    "    encoder_tokens=tokens_input[0:tensor_decoder_attn.size(-1)],\n",
    "    decoder_tokens=tokens_output[0:tensor_decoder_attn.size(-1)],\n",
    "    html_action='return'\n",
    ")\n",
    "with open(\"./out/model_view.html\", 'w') as file:\n",
    "    file.write(html_model_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58589e22-44ec-4cd1-bf40-42cc8ed65764",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_head_view = head_view(\n",
    "    encoder_attention=tensor_encoder_attn,\n",
    "    decoder_attention=tensor_decoder_attn,\n",
    "    cross_attention=tensor_cross_attn,\n",
    "    encoder_tokens=tokens_input[0:tensor_decoder_attn.size(-1)],\n",
    "    decoder_tokens=tokens_output[0:tensor_decoder_attn.size(-1)],\n",
    "    html_action='return'\n",
    ")\n",
    "with open(\"./out/head_view.html\", 'w') as file:\n",
    "    file.write(html_head_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bf51c-9872-415b-8d4f-1d6130bfe1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2016b47-3c21-4c23-af1e-4d7c39ba273e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc936ea-0246-4fdc-b1d7-817a4c5f840e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
