{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30d3ba5-5d15-4a37-8483-1592fcd6db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bertviz import head_view, model_view\n",
    "\n",
    "from transformer_implementation import Transformer, Tokenizer, TransformerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99d1ac-451d-45c8-9a5d-28799680a1b9",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1014fd-c546-4959-b9b6-996af4f2dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4a4183-8126-4b94-8130-7541b0ca4d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(\n",
      "\tself.tokenizer=<transformer_implementation.Tokenizer.Tokenizer object at 0x0000020113801050>,\n",
      "\tself.block_size=256,\n",
      "\tself.batch_size=12,\n",
      "\tself.n_layer=3,\n",
      "\tself.n_head=8,\n",
      "\tself.n_embd=256,\n",
      "\tself.dropout=0.1,\n",
      "\tself.bias=False,\n",
      "\tself.device='cuda',\n",
      "\tself.learning_rate=0.0003,\n",
      "\tself.max_iters=2000,\n",
      "\tself.eval_interval=100,\n",
      "\tself.eval_iters=50,\n",
      "\tself.visualize=True,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# init config\n",
    "config = TransformerConfig(\n",
    "    tokenizer,\n",
    "    block_size = 256,\n",
    "    batch_size = 12,\n",
    "    n_layer = 3, # 6,\n",
    "    n_head = 8,\n",
    "    # n_embd = 512,\n",
    "    max_iters = 2000,\n",
    "    eval_iters = 50,\n",
    "    eval_interval = 100,\n",
    "    visualize = True,\n",
    ")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0766891a-8164-45b0-8b7e-ce76eebaa75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encoder parameters: 28.03M\n",
      "number of Decoder parameters: 28.82M\n",
      "Total number of parameters: 56.85M\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Transformer(config)\n",
    "model.load_model(\"./out/transformer-train.pth\")\n",
    "model.eval()\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e28e8b8-a6b7-4591-9ac3-ffc8770ed362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentences, tokenizer, model, config):\n",
    "    \"\"\"\n",
    "    This function tokenizes input sentences, translates them using the provided model,\n",
    "    and decodes the output into human-readable text. It also returns the attention dictionary from the model.\n",
    "\n",
    "    Args:\n",
    "        - sentences (list[str]): List of sentences to be translated.\n",
    "        - tokenizer (Tokenizer): Tokenizer used for encoding and decoding sequences.\n",
    "        - model (Transformer): The model used for translation.\n",
    "        - config (Config): The configuration object that defines parameters like block_size.\n",
    "\n",
    "    Returns:\n",
    "        - decode_output (list[str]): List of translated sentences.\n",
    "        - attn (dict): Dictionary containing attention information from the last layer of the model.\n",
    "    \"\"\"\n",
    "    # Tokenize sentences\n",
    "    tknzr = tokenizer.encoder\n",
    "    sequences = []\n",
    "    masks =  []\n",
    "\n",
    "    # Encode each sentence and add it to the list of sequences\n",
    "    for sentence in sentences:\n",
    "        sequence = tokenizer.sequence_padding(tknzr.encode(sentence), config.block_size).unsqueeze(dim=0)\n",
    "        mask = tokenizer.generate_padding_mask(sequence)\n",
    "        sequences.append(sequence)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Concatenate the sequences into a tensor\n",
    "    sequences = torch.cat(sequences, dim=0)\n",
    "    masks = torch.cat(masks, dim=0)\n",
    "\n",
    "    # Set the model to evaluation mode and translate sentences\n",
    "    model.eval()\n",
    "    outputs, attn = model.translate_beam_search(\n",
    "        sequences.to(config.device),\n",
    "        top_k=200,\n",
    "        temperature=0.75,\n",
    "        src_mask=masks.to(config.device)\n",
    "    )\n",
    "\n",
    "    # Initialize a list to store the decoded sentences\n",
    "    decode_output = []\n",
    "    print( outputs)\n",
    "    # Decode each output sequence and add it to the list of decoded outputs\n",
    "    for output in outputs:\n",
    "        output = tokenizer.sequence_cleaner(output)\n",
    "        decode_output += [tknzr.decode(output)]\n",
    "\n",
    "    # Return the decoded sentences and the attention dictionary\n",
    "    return decode_output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a82890e5-6545-4d99-aac5-c687324c8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ['Should the judiciary be deprived of power?']\n",
    "# expected_output = ['Je suis un professeur.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d52ba69-9237-452e-923e-2749af2125ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/256tensor([[100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,\n",
      "          44351, 100264,  44351,    324, 100264, 100264, 100264, 100264, 100264,\n",
      "         100264, 100264, 100264, 100264, 100264, 100264, 100264, 100264,    320,\n",
      "         100264, 100264, 100264, 100264, 100264,  44351, 100264, 100264, 100264,\n",
      "         100264, 100264,    292,    292,  20662,     39,   8065,  82620,     13,\n",
      "             13, 100265]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "outputs, attentions = translate(input, tokenizer, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c704cd98-63d0-48cd-809c-18dd179be8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ainsi ainsiur ( ainsiicic cetteH au d√©veloppement..']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a3d80d0-2107-4e6c-b8b6-c49012308c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_attn(input, output, attentions, batch: int = 0):\n",
    "    \"\"\"\n",
    "    This function formats the attention outputs and tokenized inputs and outputs for easier interpretation and visualization.\n",
    "\n",
    "    Args:\n",
    "        - input (str): The original input sentence.\n",
    "        - output (str): The translated output sentence.\n",
    "        - attentions (dict): A dictionary containing the attention information from the model.\n",
    "        - batch (int, optional): The batch index to format. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        - tokens_input (list[str]): The tokenized input sentence, padded to max_len.\n",
    "        - tokens_output (list[str]): The tokenized output sentence, padded to max_len.\n",
    "        - tensor_encoder_attn (torch.Tensor): The attention tensor for the encoder, trimmed and reshaped.\n",
    "        - tensor_cross_attn (torch.Tensor): The cross-attention tensor, trimmed and reshaped.\n",
    "        - tensor_decoder_attn (torch.Tensor): The attention tensor for the decoder, trimmed and reshaped.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stack the attention tensors along a new dimension\n",
    "    tensor_encoder_attn = torch.stack(attentions['encoder_attn'], dim=0)\n",
    "    tensor_cross_attn = torch.stack(attentions['cross_attn'], dim=0)\n",
    "    tensor_decoder_attn = torch.stack(attentions['decoder_attn'], dim=0)\n",
    "\n",
    "    # Tokenize the input and output sentences\n",
    "    tokens_input = tokenizer.tokenize_from_str(input[batch])\n",
    "    tokens_output = tokenizer.tokenize_from_str(output[batch])\n",
    "\n",
    "    # Find the maximum length of the input and output tokens\n",
    "    max_len = min(len(tokens_input), len(tokens_output))\n",
    "\n",
    "    # If the input tokens are shorter than the max length, pad with empty strings\n",
    "    if len(tokens_input) < max_len:\n",
    "        tokens_input = tokens_input + [''] * (max_len - len(tokens_input))\n",
    "    # Otherwise, pad the output tokens with empty strings\n",
    "    else:\n",
    "        tokens_output = tokens_output + [''] * (max_len - len(tokens_output))\n",
    "\n",
    "    # Trim and reshape the attention tensors\n",
    "    tensor_encoder_attn = tensor_encoder_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "    tensor_cross_attn = tensor_cross_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "    tensor_decoder_attn = tensor_decoder_attn[:, batch:batch+1, :, 0:max_len, 0:max_len] # layers, batch, heads, seq_len, seq_len\n",
    "\n",
    "    # Return the formatted tokens and attention tensors\n",
    "    return tokens_input, tokens_output, tensor_encoder_attn, tensor_cross_attn, tensor_decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdf4df39-943a-446f-819a-e97e93129407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input,\\\n",
    "tokens_output,\\\n",
    "tensor_encoder_attn,\\\n",
    "tensor_cross_attn,\\\n",
    "tensor_decoder_attn = format_attn(input, outputs, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66cbf390-5e54-4fd6-9274-e3c9d19d4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_model_view = model_view(\n",
    "    encoder_attention=tensor_encoder_attn,\n",
    "    decoder_attention=tensor_decoder_attn,\n",
    "    cross_attention=tensor_cross_attn,\n",
    "    encoder_tokens=tokens_input[0:tensor_decoder_attn.size(-1)],\n",
    "    decoder_tokens=tokens_output[0:tensor_decoder_attn.size(-1)],\n",
    "    html_action='return'\n",
    ")\n",
    "with open(\"./out/model_view.html\", 'w') as file:\n",
    "    file.write(html_model_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58589e22-44ec-4cd1-bf40-42cc8ed65764",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_head_view = head_view(\n",
    "    encoder_attention=tensor_encoder_attn,\n",
    "    decoder_attention=tensor_decoder_attn,\n",
    "    cross_attention=tensor_cross_attn,\n",
    "    encoder_tokens=tokens_input[0:tensor_decoder_attn.size(-1)],\n",
    "    decoder_tokens=tokens_output[0:tensor_decoder_attn.size(-1)],\n",
    "    html_action='return'\n",
    ")\n",
    "with open(\"./out/head_view.html\", 'w') as file:\n",
    "    file.write(html_head_view.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bf51c-9872-415b-8d4f-1d6130bfe1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
