Search.setIndex({"docnames": ["index", "utils.DataLoaderFactory", "utils.Decoder", "utils.DecoderBlock", "utils.Encoder", "utils.EncoderBlock", "utils.FeedForward", "utils.LayerNorm", "utils.MultiHeadAttention", "utils.Tokenizer", "utils.Transformer", "utils.TransformerConfig"], "filenames": ["index.rst", "utils.DataLoaderFactory.rst", "utils.Decoder.rst", "utils.DecoderBlock.rst", "utils.Encoder.rst", "utils.EncoderBlock.rst", "utils.FeedForward.rst", "utils.LayerNorm.rst", "utils.MultiHeadAttention.rst", "utils.Tokenizer.rst", "utils.Transformer.rst", "utils.TransformerConfig.rst"], "titles": ["Welcome to Transformer\u2019s documentation!", "DataLoaderFactory Class", "Decoder Class", "DecoderBlock Class", "Encoder Class", "EncoderBlock Class", "FeedForward Class", "LayerNorm Class", "MultiHeadAttention Class", "Tokenizer Class", "Transformer Class", "TransformerConfig Class"], "terms": {"index": 0, "modul": [0, 2, 4, 7, 8], "search": 0, "page": 0, "t": [2, 8], "class": 0, "util": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ndim": 7, "int": [1, 2, 4, 7, 8, 9, 11], "bia": [2, 3, 4, 5, 6, 7, 10, 11], "bool": [2, 4, 7, 8, 11], "A": [1, 2, 3, 4, 5, 6, 7, 9], "layer": [2, 3, 4, 5, 6, 7, 8], "normal": [3, 5, 7], "option": [4, 7, 8, 9], "thi": [2, 4, 7, 8, 10, 11], "implement": [2, 3, 4, 5, 6, 7, 8, 10], "allow": [7, 9], "turn": 7, "off": 7, "term": 7, "which": [7, 10], "i": [2, 3, 4, 5, 7, 8, 9, 10, 11], "directli": 7, "support": 7, "pytorch": [1, 7], "": [3, 7, 9, 10], "function": [6, 7], "attribut": [2, 3, 4, 5, 6, 7, 8, 10, 11], "weight": [2, 4, 7], "learnabl": 7, "initi": 7, "an": [1, 2, 4, 7, 11], "all": 7, "ones": 7, "tensor": [2, 3, 4, 5, 6, 7, 8, 9, 10], "bias": 7, "zero": 7, "argument": 7, "constructor": 7, "true": [2, 4, 7, 11], "otherwis": 7, "set": [7, 11], "none": [2, 7, 8], "arg": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "integ": 7, "dimens": [2, 7], "input": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "vector": 7, "boolean": 7, "add": [7, 9], "output": [2, 3, 4, 5, 6, 7, 8, 10], "forward": [2, 3, 4, 5, 6, 7, 8, 10], "defin": [2, 3, 4, 5, 6, 7, 10], "comput": [2, 3, 4, 5, 6, 7, 8, 10], "perform": [2, 3, 4, 5, 6, 7, 10], "everi": [2, 3, 4, 5, 6, 7, 10], "call": [2, 3, 4, 5, 6, 7, 10], "The": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11], "return": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "layernorm": [0, 3, 5, 11], "token": [0, 1, 2, 4, 11], "encod": [0, 1, 2, 3, 5, 9, 10, 11], "decod": [0, 3, 9, 10, 11], "text": [9, 10], "sequenc": [1, 2, 4, 8, 9, 10, 11], "sequenceclearn": [], "method": [1, 9], "remov": 9, "bo": 9, "pad": 9, "eo": 9, "special": 9, "from": [1, 2, 3, 4, 9, 11], "torch": [2, 3, 4, 5, 6, 9, 10], "list": 9, "clean": 9, "sequencepad": [], "max_siz": 9, "512": [9, 11], "ensur": 9, "length": [1, 9], "within": 9, "maximum": [1, 9], "size": [1, 2, 9, 11], "union": 9, "default": [2, 4, 9, 11], "process": 9, "ad": 9, "limit": 9, "vocabs": [], "vocabulari": [2, 9, 11], "transformerconfig": 0, "ani": 11, "block_siz": [1, 2, 4, 10, 11], "batch_siz": [1, 8, 11], "12": 11, "n_layer": [2, 4, 10, 11], "1": [2, 11], "n_head": [8, 11], "2": 11, "n_embd": [2, 3, 4, 5, 6, 8, 10, 11], "128": 11, "dropout": [2, 4, 6, 8, 10, 11], "float": [8, 11], "0": [2, 11], "fals": 11, "data": 11, "store": 11, "configur": [2, 3, 4, 5, 6, 10, 11], "transform": [2, 3, 4, 5, 6, 11], "model": [2, 3, 4, 5, 6, 10, 11], "instanc": 11, "number": [2, 4, 8, 11], "each": [2, 3, 4, 5, 11], "batch": [1, 11], "vocab_s": [2, 4, 9, 10, 11], "total": [2, 4, 11], "It": [10, 11], "block": [3, 5, 11], "n": 11, "head": [3, 5, 8, 11], "attent": [3, 5, 8, 10, 11], "embed": [2, 4, 8, 11], "origin": [1, 11], "paper": 11, "rate": [8, 11], "us": [1, 2, 4, 10, 11], "indic": [2, 8, 11], "whether": [1, 8, 11], "linear": [2, 6, 8, 11], "If": [2, 4, 11], "similar": 11, "gpt": 11, "bit": 11, "better": 11, "faster": 11, "devic": [1, 11], "str": [1, 11], "run": 11, "cpu": [1, 11], "cuda": [1, 11], "gpu": [1, 11], "avail": [8, 11], "learning_r": 11, "learn": 11, "optim": 11, "3e": 11, "4": 11, "eval_interv": 11, "step": 11, "between": [6, 11], "valid": 11, "dataset": [1, 11], "eval_it": 11, "epoch": 11, "20": 11, "properti": 11, "dataloaderfactori": 0, "instanti": 1, "dataload": 1, "differ": 1, "split": 1, "huggingfac": 1, "ha": 1, "depend": 1, "we": [1, 2, 4], "get_batch": 1, "choos": 1, "correct": 1, "yield": 1, "train": 1, "val": 1, "test": 1, "dict": 1, "dictionari": [1, 2, 4], "kei": [1, 8], "target": [1, 10], "translat": 1, "contain": 1, "sequence_clearn": 9, "sequence_pad": 9, "translationdataset": [0, 1], "creat": 1, "librari": 1, "custom": 1, "tiktoken": 1, "multiheadattent": [0, 3, 5], "config": [2, 3, 4, 5, 6, 8, 10], "multi": [3, 5, 8], "appli": 8, "mechan": [3, 5, 8, 10], "doesn": 8, "mask": 8, "over": [3, 8], "score": 8, "dimension": 8, "q_attn": 8, "nn": [2, 4, 6, 8], "queri": 8, "project": 8, "k_attn": 8, "v_attn": 8, "valu": 8, "c_proj": [6, 8], "attn_dropout": 8, "resid_dropout": 8, "residu": [3, 5, 8], "connect": [3, 5, 6, 8], "flash": 8, "flag": 8, "q_x": 8, "k_x": 8, "v_x": 8, "pass": [2, 3, 4, 5, 6, 8], "shape": [2, 8], "seq_length": 8, "emb_dim": 8, "y": 8, "after": 8, "scaled_dot_product_attent": 8, "q": 8, "k": 8, "v": 8, "scale": 8, "dot": 8, "product": 8, "num_head": 8, "feedforward": [0, 3, 5], "posit": [2, 3, 4, 5, 6], "wise": [3, 5, 6], "feed": [2, 3, 5, 6], "neural": 6, "network": [3, 5, 6], "ffnn": 6, "consist": [2, 3, 4, 5, 6], "two": [5, 6], "gelu": 6, "activ": 6, "follow": [2, 3, 4, 5, 6], "regular": 6, "c_fc": 6, "first": [2, 3, 4, 6], "fulli": [3, 5, 6], "second": [3, 6], "object": [2, 3, 4, 5, 6, 10], "x": [3, 5, 6], "encoderblock": [0, 4], "singl": [3, 5], "sub": [3, 5], "self": [3, 5], "There": [3, 5], "around": [3, 5], "ln_1": [3, 5], "befor": [3, 5], "attn": 5, "ln_2": [3, 5], "ffw": [3, 5], "decoderblock": [0, 2], "three": 3, "attn1": 3, "attn2": 3, "attend": 3, "ln_3": 3, "encoder_output": 3, "last": 3, "part": [2, 4], "sever": [2, 4], "arrang": [2, 4], "goe": [2, 4], "through": [2, 4], "moduledict": [2, 4], "make": [2, 4], "up": [2, 4], "idx": [2, 4], "against": [], "loss": 10, "calcul": 10, "logit": [2, 4, 10], "were": [], "provid": [], "get_num_param": [2, 4], "non_embed": [2, 4], "paramet": [2, 4], "For": [2, 4], "non": [2, 4], "count": [2, 4], "get": [2, 4], "subtract": [2, 4], "would": [2, 4], "too": [2, 4], "except": [2, 4], "due": [2, 4], "share": [2, 4], "param": [2, 4], "ar": [2, 4], "actual": [2, 4], "final": [2, 4], "so": [2, 4], "includ": [2, 4, 10], "them": [2, 4], "exclud": [2, 4], "lm_head": 2, "map": 2, "enc_output": 2, "gener": 2, "max_new_token": 2, "temperatur": 2, "top_k": 2, "take": 2, "condit": 2, "longtensor": 2, "b": 2, "complet": 2, "time": 2, "predict": 2, "back": 2, "most": 2, "like": 2, "you": 2, "ll": 2, "want": 2, "sure": 2, "eval": 2, "mode": 2, "oper": 2, "both": 10, "transduct": 10, "primarili": 10, "task": 10, "requir": 10, "understand": 10, "context": 10, "relationship": 10, "among": 10, "word": 10, "src": 10, "tgt": 10, "basi": 10}, "objects": {"utils": [[1, 0, 1, "", "DataLoaderFactory"], [2, 0, 1, "", "Decoder"], [3, 0, 1, "", "DecoderBlock"], [4, 0, 1, "", "Encoder"], [5, 0, 1, "", "EncoderBlock"], [6, 0, 1, "", "FeedForward"], [7, 0, 1, "", "LayerNorm"], [8, 0, 1, "", "MultiHeadAttention"], [9, 0, 1, "", "Tokenizer"], [10, 0, 1, "", "Transformer"], [11, 0, 1, "", "TransformerConfig"], [1, 0, 1, "", "TranslationDataset"]], "utils.DataLoaderFactory": [[1, 1, 1, "", "get_batch"]], "utils.Decoder": [[2, 1, 1, "", "forward"], [2, 1, 1, "", "generate"], [2, 1, 1, "", "get_num_params"]], "utils.DecoderBlock": [[3, 1, 1, "", "forward"]], "utils.Encoder": [[4, 1, 1, "", "forward"], [4, 1, 1, "", "get_num_params"]], "utils.EncoderBlock": [[5, 1, 1, "", "forward"]], "utils.FeedForward": [[6, 1, 1, "", "forward"]], "utils.LayerNorm": [[7, 1, 1, "", "forward"]], "utils.MultiHeadAttention": [[8, 1, 1, "", "forward"], [8, 1, 1, "", "scaled_dot_product_attention"]], "utils.Tokenizer": [[9, 1, 1, "", "sequence_clearner"], [9, 1, 1, "", "sequence_padding"], [9, 1, 1, "", "vocab_size"]], "utils.Transformer": [[10, 1, 1, "", "forward"]], "utils.TransformerConfig": [[11, 2, 1, "", "vocab_size"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"]}, "titleterms": {"welcom": 0, "transform": [0, 10], "": 0, "document": 0, "indic": 0, "tabl": 0, "layernorm": 7, "modul": [], "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "token": 9, "content": 0, "transformerconfig": 11, "dataloaderfactori": 1, "multiheadattent": 8, "feedforward": 6, "encoderblock": 5, "decoderblock": 3, "encod": 4, "decod": 2}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"LayerNorm Class": [[7, "layernorm-class"]], "Tokenizer Class": [[9, "tokenizer-class"]], "TransformerConfig Class": [[11, "transformerconfig-class"]], "DataLoaderFactory Class": [[1, "dataloaderfactory-class"]], "MultiHeadAttention Class": [[8, "multiheadattention-class"]], "FeedForward Class": [[6, "feedforward-class"]], "DecoderBlock Class": [[3, "decoderblock-class"]], "EncoderBlock Class": [[5, "encoderblock-class"]], "Welcome to Transformer\u2019s documentation!": [[0, "welcome-to-transformer-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "Transformer Class": [[10, "transformer-class"]], "Decoder Class": [[2, "decoder-class"]], "Encoder Class": [[4, "encoder-class"]]}, "indexentries": {"decoder (class in utils)": [[2, "utils.Decoder"]], "forward() (utils.decoder method)": [[2, "utils.Decoder.forward"]], "generate() (utils.decoder method)": [[2, "utils.Decoder.generate"]], "get_num_params() (utils.decoder method)": [[2, "utils.Decoder.get_num_params"]], "encoder (class in utils)": [[4, "utils.Encoder"]], "forward() (utils.encoder method)": [[4, "utils.Encoder.forward"]], "get_num_params() (utils.encoder method)": [[4, "utils.Encoder.get_num_params"]]}})