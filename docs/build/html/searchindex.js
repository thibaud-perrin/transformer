Search.setIndex({"docnames": ["index", "utils.DataLoaderFactory", "utils.DecoderBlock", "utils.EncoderBlock", "utils.FeedForward", "utils.LayerNorm", "utils.MultiHeadAttention", "utils.Tokenizer", "utils.TransformerConfig"], "filenames": ["index.rst", "utils.DataLoaderFactory.rst", "utils.DecoderBlock.rst", "utils.EncoderBlock.rst", "utils.FeedForward.rst", "utils.LayerNorm.rst", "utils.MultiHeadAttention.rst", "utils.Tokenizer.rst", "utils.TransformerConfig.rst"], "titles": ["Welcome to Transformer\u2019s documentation!", "DataLoaderFactory Class", "DecoderBlock Class", "EncoderBlock Class", "FeedForward Class", "LayerNorm Class", "MultiHeadAttention Class", "Tokenizer Class", "TransformerConfig Class"], "terms": {"index": 0, "modul": [0, 5, 6], "search": 0, "page": 0, "t": 6, "class": 0, "util": [1, 2, 3, 4, 5, 6, 7, 8], "ndim": 5, "int": [1, 5, 6, 7, 8], "bia": [2, 3, 4, 5, 8], "bool": [5, 6, 8], "A": [1, 2, 3, 4, 5, 7], "layer": [2, 3, 4, 5, 6], "normal": [2, 3, 5], "option": [5, 6, 7], "thi": [5, 6, 8], "implement": [2, 3, 4, 5, 6], "allow": [5, 7], "turn": 5, "off": 5, "term": 5, "which": 5, "i": [2, 3, 5, 6, 7, 8], "directli": 5, "support": 5, "pytorch": [1, 5], "": [2, 5, 7], "function": [4, 5], "attribut": [2, 3, 4, 5, 6, 8], "weight": 5, "learnabl": 5, "initi": 5, "an": [1, 5, 8], "all": 5, "ones": 5, "tensor": [2, 3, 4, 5, 6, 7], "bias": 5, "zero": 5, "argument": 5, "constructor": 5, "true": [5, 8], "otherwis": 5, "set": [5, 8], "none": [5, 6], "arg": [1, 2, 3, 4, 5, 6, 7], "integ": 5, "dimens": 5, "input": [1, 2, 3, 4, 5, 6, 7], "vector": 5, "boolean": 5, "add": [5, 7], "output": [2, 3, 4, 5, 6], "forward": [2, 3, 4, 5, 6], "defin": [2, 3, 4, 5], "comput": [2, 3, 4, 5, 6], "perform": [2, 3, 4, 5], "everi": [2, 3, 4, 5], "call": [2, 3, 4, 5], "The": [1, 2, 3, 4, 5, 7, 8], "return": [2, 3, 4, 5, 6, 7, 8], "layernorm": [0, 2, 3, 8], "token": [0, 1, 8], "encod": [1, 2, 3, 7, 8], "decod": [2, 7, 8], "text": 7, "sequenc": [1, 6, 7, 8], "sequenceclearn": [], "method": [1, 7], "remov": 7, "bo": 7, "pad": 7, "eo": 7, "special": 7, "from": [1, 2, 7, 8], "torch": [2, 3, 4, 7], "list": 7, "clean": 7, "sequencepad": [], "max_siz": 7, "512": [7, 8], "ensur": 7, "length": [1, 7], "within": 7, "maximum": [1, 7], "size": [1, 7, 8], "union": 7, "default": [7, 8], "process": 7, "ad": 7, "limit": 7, "vocabs": [], "vocabulari": [7, 8], "transformerconfig": 0, "ani": 8, "block_siz": [1, 8], "batch_siz": [1, 6, 8], "12": 8, "n_layer": 8, "1": 8, "n_head": [6, 8], "2": 8, "n_embd": [2, 3, 4, 6, 8], "128": 8, "dropout": [4, 6, 8], "float": [6, 8], "0": 8, "fals": 8, "data": 8, "store": 8, "configur": [2, 3, 4, 8], "transform": [2, 3, 4, 8], "model": [2, 3, 4, 8], "instanc": 8, "number": [6, 8], "each": [2, 3, 8], "batch": [1, 8], "vocab_s": [7, 8], "total": 8, "It": 8, "block": [2, 3, 8], "n": 8, "head": [2, 3, 6, 8], "attent": [2, 3, 6, 8], "embed": [6, 8], "origin": [1, 8], "paper": 8, "rate": [6, 8], "us": [1, 8], "indic": [6, 8], "whether": [1, 6, 8], "linear": [4, 6, 8], "If": 8, "similar": 8, "gpt": 8, "bit": 8, "better": 8, "faster": 8, "devic": [1, 8], "str": [1, 8], "run": 8, "cpu": [1, 8], "cuda": [1, 8], "gpu": [1, 8], "avail": [6, 8], "learning_r": 8, "learn": 8, "optim": 8, "3e": 8, "4": 8, "eval_interv": 8, "step": 8, "between": [4, 8], "valid": 8, "dataset": [1, 8], "eval_it": 8, "epoch": 8, "20": 8, "properti": 8, "dataloaderfactori": 0, "instanti": 1, "dataload": 1, "differ": 1, "split": 1, "huggingfac": 1, "ha": 1, "depend": 1, "we": 1, "get_batch": 1, "choos": 1, "correct": 1, "yield": 1, "train": 1, "val": 1, "test": 1, "dict": 1, "dictionari": 1, "kei": [1, 6], "target": 1, "translat": 1, "contain": 1, "sequence_clearn": 7, "sequence_pad": 7, "translationdataset": [0, 1], "creat": 1, "librari": 1, "custom": 1, "tiktoken": 1, "multiheadattent": [0, 2, 3], "config": [2, 3, 4, 6], "multi": [2, 3, 6], "appli": 6, "mechan": [2, 3, 6], "doesn": 6, "mask": 6, "over": [2, 6], "score": 6, "dimension": 6, "q_attn": 6, "nn": [4, 6], "queri": 6, "project": 6, "k_attn": 6, "v_attn": 6, "valu": 6, "c_proj": [4, 6], "attn_dropout": 6, "resid_dropout": 6, "residu": [2, 3, 6], "connect": [2, 3, 4, 6], "flash": 6, "flag": 6, "q_x": 6, "k_x": 6, "v_x": 6, "pass": [2, 3, 4, 6], "shape": 6, "seq_length": 6, "emb_dim": 6, "y": 6, "after": 6, "scaled_dot_product_attent": 6, "q": 6, "k": 6, "v": 6, "scale": 6, "dot": 6, "product": 6, "num_head": 6, "feedforward": [0, 2, 3], "posit": [2, 3, 4], "wise": [2, 3, 4], "feed": [2, 3, 4], "neural": 4, "network": [2, 3, 4], "ffnn": 4, "consist": [2, 3, 4], "two": [3, 4], "gelu": 4, "activ": 4, "follow": [2, 3, 4], "regular": 4, "c_fc": 4, "first": [2, 4], "fulli": [2, 3, 4], "second": [2, 4], "object": [2, 3, 4], "x": [2, 3, 4], "encoderblock": 0, "singl": [2, 3], "sub": [2, 3], "self": [2, 3], "There": [2, 3], "around": [2, 3], "ln_1": [2, 3], "befor": [2, 3], "attn": 3, "ln_2": [2, 3], "ffw": [2, 3], "decoderblock": 0, "three": 2, "attn1": 2, "attn2": 2, "attend": 2, "ln_3": 2, "encoder_output": 2, "last": 2}, "objects": {"utils": [[1, 0, 1, "", "DataLoaderFactory"], [2, 0, 1, "", "DecoderBlock"], [3, 0, 1, "", "EncoderBlock"], [4, 0, 1, "", "FeedForward"], [5, 0, 1, "", "LayerNorm"], [6, 0, 1, "", "MultiHeadAttention"], [7, 0, 1, "", "Tokenizer"], [8, 0, 1, "", "TransformerConfig"], [1, 0, 1, "", "TranslationDataset"]], "utils.DataLoaderFactory": [[1, 1, 1, "", "get_batch"]], "utils.DecoderBlock": [[2, 1, 1, "", "forward"]], "utils.EncoderBlock": [[3, 1, 1, "", "forward"]], "utils.FeedForward": [[4, 1, 1, "", "forward"]], "utils.LayerNorm": [[5, 1, 1, "", "forward"]], "utils.MultiHeadAttention": [[6, 1, 1, "", "forward"], [6, 1, 1, "", "scaled_dot_product_attention"]], "utils.Tokenizer": [[7, 1, 1, "", "sequence_clearner"], [7, 1, 1, "", "sequence_padding"], [7, 1, 1, "", "vocab_size"]], "utils.TransformerConfig": [[8, 2, 1, "", "vocab_size"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"]}, "titleterms": {"welcom": 0, "transform": 0, "": 0, "document": 0, "indic": 0, "tabl": 0, "layernorm": 5, "modul": [], "class": [1, 2, 3, 4, 5, 6, 7, 8], "token": 7, "content": 0, "transformerconfig": 8, "dataloaderfactori": 1, "multiheadattent": 6, "feedforward": 4, "encoderblock": 3, "decoderblock": 2}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"LayerNorm Class": [[5, "layernorm-class"]], "Tokenizer Class": [[7, "tokenizer-class"]], "TransformerConfig Class": [[8, "transformerconfig-class"]], "DataLoaderFactory Class": [[1, "dataloaderfactory-class"]], "MultiHeadAttention Class": [[6, "multiheadattention-class"]], "FeedForward Class": [[4, "feedforward-class"]], "Welcome to Transformer\u2019s documentation!": [[0, "welcome-to-transformer-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "DecoderBlock Class": [[2, "decoderblock-class"]], "EncoderBlock Class": [[3, "encoderblock-class"]]}, "indexentries": {"decoderblock (class in utils)": [[2, "utils.DecoderBlock"]], "forward() (utils.decoderblock method)": [[2, "utils.DecoderBlock.forward"]], "encoderblock (class in utils)": [[3, "utils.EncoderBlock"]], "forward() (utils.encoderblock method)": [[3, "utils.EncoderBlock.forward"]]}})